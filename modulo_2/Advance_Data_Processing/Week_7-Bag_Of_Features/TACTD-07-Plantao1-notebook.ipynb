{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MBA em Ciência de Dados\n",
    "## Técnicas Avançadas de Captura e Tratamento de Dados\n",
    "\n",
    "\n",
    "### <span style=\"color:darkred\">Módulo VII - Dados não estruturados: sinais e imagens</span>\n",
    "\n",
    "### <span style=\"color:darkred\">Exercícios</span>\n",
    "\n",
    "Moacir Antonelli Ponti\n",
    "\n",
    "CeMEAI - ICMC/USP São Carlos\n",
    "\n",
    "---\n",
    "\n",
    "#### <span style=\"color:red\">Recomenda-se fortemente que os exercícios sejam feitos sem consultar as respostas antecipadamente.</span>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# carregando as bibliotecas necessárias\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 3)\n",
    "\n",
    "Carregue os dados do arquivo `sinais2.csv` utilizando\n",
    "\n",
    "`signals = np.genfromtxt(arquivo, delimiter=',').astype(np.float32)`.\n",
    "\n",
    "O array resultante possui um sinal por linha, i.e. `sinal[i]`\n",
    "\n",
    "Utilizando os sinais carregados utilize a `np.fft.fft()` para obter a Transformada de Fourier dos sinais. Depois, considerando apenas frequências até 50, calcule quais são as 4 frequências de maior valor de magnitude (obtido pelo `np.abs()`). Aqui não queremos os valores da magnitude, mas a quais frequências (índices) elas se referem. Para complementar a análise, plote as magnitudes das transformadas até a frequência 50.\n",
    "\n",
    "Analisando as frequências de maior magnitude temos as frequências que mais caracterizam o sinal. Considerando as 4 frequências computadas anteriormente, podemos dividir os sinais em categorias distintas. Nesse sentido, qual análise abaixo está correta?\n",
    "\n",
    "(a) O sinal 4 possui frequências inferiores quando comparado com os demais, indicando que o sinal 4 é provavalmente  dependente sequencialmente, enquanto os demais são i.i.d.; assim podemos dividí-los em duas categorias: sinal 4 e sinais 0, 1, 2 e 3.<br>\n",
    "(b) O sinal 3 possui frequências mais significativas 20 Hz ou superior, indicando que é um sinal com maior qualidade de aquisição, e assim podemos categorizar em: sinal 3, e sinais 0, 1, 2 e 4.<br>\n",
    "(c) Todas as frequências estão abaixo de 50 Hz, sendo assim podemos dizer que os sinais são todos similares, sendo impossível dividí-los em categorias.<br>\n",
    "(d) O sinal 3 possui frequências mais significativas 20 Hz ou superior, possuindo transições mais rápidas de valores do que os outros com frequências caracerísticas menores do que 12Hz; e assim podemos categorizar em: sinal 3, e sinais 0, 1, 2 e 4.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 9000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pode fazer com pandas tbm\n",
    "# pd.read_csv(\"dados/sinais2.csv\", header=None)\n",
    "signals = np.genfromtxt('./dados/sinais2.csv', delimiter=',').astype(np.float32)\n",
    "signals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 [10 11  8  6]\n",
      "1 [10  9  8  7]\n",
      "2 [7 5 9 8]\n",
      "3 [28 39 21 20]\n",
      "4 [3 8 2 6]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(signals)):\n",
    "    Fi = np.abs(np.fft.fft(signals[i]))\n",
    "    Fi_50 = Fi[:50]\n",
    "    ind = np.argpartition(Fi_50, -4)[-4:]\n",
    "    print(i, ind)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 4)\n",
    " \n",
    "Considerando os mesmos sinais carregados, compute as características: entropia da energia (com 10 blocos), taxa de cruzamentos por zero, entropia espectral (com 10 blocos), formando um vetor com 3 características para cada sinal.\n",
    "\n",
    "Após isso, compute a matriz de distâncias entre os sinais considerando a distância L1, i.e., a soma dos valores absolutos das diferenças entre dois vetores $A$ e $B$:\n",
    "\n",
    "$$\\sum_i |A_i - B_i|$$\n",
    "\n",
    "Da matriz, que indica a dissimilaridade entre pares de sinais, aplique uma soma na direção do eixo 0 (axis=0) e depois arredonde para inteiro `np.round(,0)`. Quais valores foram obtidos para cada sinal?\n",
    "\n",
    "(a) Sinais 0, 1, 2 e 4, soma 2; Sinal 3, soma 6.<br>\n",
    "(b) Sinais 0 e 4, soma 3; Sinais 1 e 2, soma 2; Sinal 3, soma 6.<br>\n",
    "(c) Sinais 0, 1, e 2, soma 2; Sinal 3, soma 6; Sinal 4, soma 3.<br>\n",
    "(d) Sinais 0, 1, e 2, soma 1; Sinal 3, soma 3; Sinal 4, soma 6.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropia_energia(sinal, n_blocos=10):\n",
    "    '''Entropia da energia do sinal'''\n",
    "    # energia total \n",
    "    energia_sinal = np.sum(sinal ** 2)\n",
    "    M = len(sinal)\n",
    "    \n",
    "    # calcula janelas dentro do sinal\n",
    "    M_janelas = int(np.floor(M / n_blocos))\n",
    "    # verifica se tamanho dos blocos \n",
    "    # é multiplo do tamanho do sinal\n",
    "    if M != M_janelas * n_blocos:\n",
    "        sinal = sinal[0:M_janelas * n_blocos]\n",
    "\n",
    "    # monta matriz [M_janelas x n_blocos]\n",
    "    janelas = sinal.reshape(M_janelas, n_blocos, order='F').copy()\n",
    "    \n",
    "    # Computa energias de cada janela (normalizada pela do sinal)\n",
    "    e_janelas = np.sum(janelas ** 2, axis=0) / (energia_sinal + 0.0001)\n",
    "    #print(e_janelas)\n",
    "\n",
    "    # Computa entropia entre energias das janelas\n",
    "    entropia = -np.sum(e_janelas * np.log2(e_janelas + 0.0001))\n",
    "    return entropia\n",
    "\n",
    "def taxa_cruzamentos_por_zero(sinal):\n",
    "    '''Cruzamentos por zero em um intervalo de tempo '''\n",
    "    M = len(sinal)\n",
    "    cont_zero = np.sum(np.abs(np.diff(np.sign(sinal)))) / 2\n",
    "    return np.float64(cont_zero) / np.float64(M - 1.0)\n",
    "\n",
    "def entropia_espectral(sinal, n_blocos=10):\n",
    "    \"\"\"Computes the spectral entropy\"\"\"\n",
    "    \n",
    "    fft_abs = np.abs(np.fft.fft(sinal))\n",
    "    \n",
    "    entropia_esp = entropia_energia(fft_abs, n_blocos=n_blocos)\n",
    "\n",
    "    return entropia_esp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "funcs = [entropia_energia, taxa_cruzamentos_por_zero, entropia_espectral]\n",
    "features = np.zeros((len(signals), len(funcs)))\n",
    "\n",
    "for idx_signal, signal in enumerate(signals):\n",
    "    for idx_func, func in enumerate(funcs):\n",
    "        value = func(signal)\n",
    "        features[idx_signal, idx_func] = value\n",
    "\n",
    "# Pode ser interessante visualizar os dados com DataFrame para entender o que está acontecendo\n",
    "pd.DataFrame(features, columns=[\"entropia_energia\", \"taxa_cruzamentos_por_zero\", \"entropia_espectral\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.08820419, 0.16471197, 1.55867705, 0.56184067],\n",
       "       [0.08820419, 0.        , 0.11717896, 1.55371289, 0.47363648],\n",
       "       [0.16471197, 0.11717896, 0.        , 1.60484023, 0.42113137],\n",
       "       [1.55867705, 1.55371289, 1.60484023, 0.        , 1.63633509],\n",
       "       [0.56184067, 0.47363648, 0.42113137, 1.63633509, 0.        ]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmat = np.zeros((len(signals), len(signals)))\n",
    "for idx_signal1, feat1 in enumerate(features):\n",
    "    for idx_signal2, feat2 in enumerate(features):\n",
    "        dmat[idx_signal1, idx_signal2] = np.abs(feat1 - feat2).sum()\n",
    "dmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 6., 3.])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dmat.sum(axis=0).round(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 5)\n",
    "\n",
    "Carregue as seguintes imagens da base de dados flickr_map_training:\n",
    "\n",
    "`\n",
    "img1 = imageio.imread(\"dados/flickr_map_training/107.jpg\")\n",
    "img2 = imageio.imread(\"dados/flickr_map_training/101.jpg\")\n",
    "img3 = imageio.imread(\"dados/flickr_map_training/112.jpg\")\n",
    "img4 = imageio.imread(\"dados/flickr_map_training/303.jpg\")\n",
    "img5 = imageio.imread(\"dados/flickr_map_training/400.jpg\")`\n",
    "\n",
    "Implemente um descritor de cor que computa um histograma utilizando a composição dos canais RGB em um único canal utilizando a seguinte operação, sendo R, G e B as matrizes relativas a cada canal de cor:\n",
    "\n",
    "$$I = R\\cdot0.3 +G\\cdot0.59 +B\\cdot0.11$$\n",
    "\n",
    "Permita definir o número de bins do histograma por meio da sua função e, antes de retornar, normalize o histograma dividindo pela soma.\n",
    "\n",
    "Depois, calcule a distância entre img1 carregada e as outras imagens (2, 3, 4, 5) utilizando: 16 bins e 4 bins. Qual foram as duas imagens mais similares, da mais próxima para a mais distante, nos dois casos?\n",
    "\n",
    "(a) 16 bins: img2, img4 ; 4 bins: img2, img3<br>\n",
    "(a) 16 bins: img2, img3 ; 4 bins: img4, img3<br>\n",
    "(b) 16 bins: img2, img3 ; 4 bins: img2, img4<br>\n",
    "(d) 16 bins: img4, img2 ; 4 bins: img4, img3<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "img1 = imageio.imread(\"dados/flickr_map_training/107.jpg\")\n",
    "img2 = imageio.imread(\"dados/flickr_map_training/101.jpg\")\n",
    "img3 = imageio.imread(\"dados/flickr_map_training/112.jpg\")\n",
    "img4 = imageio.imread(\"dados/flickr_map_training/303.jpg\")\n",
    "img5 = imageio.imread(\"dados/flickr_map_training/400.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histograma_global_intensity(img, n_colors):\n",
    "    img_int = img[:,:,0].astype(float)*0.3 + img[:,:,1].astype(float)*0.59 + img[:,:,2].astype(float)*0.11\n",
    "    hist,_ = np.histogram(img_int, bins=n_colors)\n",
    "    # normaliza o vetor resultante pela soma dos valores\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 0.0001)        \n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 255\n",
      "0 255\n",
      "0 255\n",
      "0 255\n",
      "0 255\n"
     ]
    }
   ],
   "source": [
    "# Mostrando que todas as imagens tem o mesmo min/max, que vai resultar\n",
    "# numa binnização igual (com cortes iguais para cada bin)\n",
    "for img in all_imgs:\n",
    "    print(img.min(), img.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_colors = 16\n",
    "\n",
    "# Fazendo através de uma função para re-utilizar o código\n",
    "def ex5_dist(n_colors):\n",
    "    features = []\n",
    "    all_imgs = [img1, img2, img3, img4, img5]\n",
    "    for img in all_imgs:\n",
    "        features.append(histograma_global_intensity(img, n_colors))\n",
    "\n",
    "    dists = []\n",
    "    for feat in features:\n",
    "        dist = np.abs(features[0] - feat).sum()\n",
    "        dists.append(dist)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(np.arange(10))\n",
    "# sns.histplot(2 + np.arange(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.22952025985165178,\n",
       " 0.8369060998124469,\n",
       " 0.7622912638468645,\n",
       " 0.9559461472638263]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex5_dist(16)  # 2, 4 são as com menor distância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0,\n",
       " 0.14886455508209526,\n",
       " 0.5596221968952861,\n",
       " 0.6472747798467804,\n",
       " 0.7926671751897034]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex5_dist(4)  # 2, 3 são as com menor distância"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 6)\n",
    "\n",
    "Vamos repetir o procedimento da questão anterior, agora utilizando o descritor de texturas LBP visto em aula. Utilizaremos uma função que também realiza uma normalização dos valores máximos das imagens, bem como permite definir o raio, número de pontos e quantidade de bins para esse descritor, conforme abaixo.\n",
    "\n",
    "Calcule a distância L1 entre img1 carregada e as outras imagens utilizando o descritor LBP com os seguintes parâmetros:\n",
    "* número de pontos = 14\n",
    "* raio = 2\n",
    "* bins = 16\n",
    "\n",
    "Quais foram as três imagens mais similares, da mais próxima para a mais distante?\n",
    "\n",
    "(a) img3, img2, img5<br>\n",
    "(b) img2, img3, img4<br>\n",
    "(c) img3, img5, img2<br>\n",
    "(d) img5, img3, img2<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import feature\n",
    "\n",
    "def lbp_features(img, points=8, radius=1, n_bins=10):\n",
    "    # LBP opera em imagens de um só canal, aqui vamos converter \n",
    "    # RGB para escala de cinza usando o método Luminance\n",
    "    img = np.array(img, dtype=np.float64, copy=False)\n",
    "    if (len(img.shape) > 2):\n",
    "        img = img[:,:,0]*0.3 + img[:,:,1]*0.59 + img[:,:,2]*0.11\n",
    "    \n",
    "    # normaliza a imagem para ter máximo = 255\n",
    "    if (np.max(img) > 0):\n",
    "        img = ((img/np.max(img))*255).astype(np.uint8)\n",
    "    \n",
    "    # aqui definimos o numero de pontos e o raio, padrao = 8, 1\n",
    "    lbp = feature.local_binary_pattern(img.astype(np.uint8), points, radius, method=\"uniform\")\n",
    "    \n",
    "    # lbp retorna um matriz com os códigos, então devemos extraír o histograma\n",
    "    (hist, _) = np.histogram(lbp.ravel(), bins=np.arange(0, n_bins+1), range=(0, n_bins))\n",
    "\n",
    "    # normaliza o histograma\n",
    "    hist = hist.astype(\"float\")\n",
    "    hist /= (hist.sum() + 1e-6)\n",
    "    # return the histogram of Local Binary Patterns\n",
    "\n",
    "    return hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reutilizando o código da função 5, so mudando a função\n",
    "def ex6_dist():\n",
    "    features = []\n",
    "    all_imgs = [img1, img2, img3, img4, img5]\n",
    "    for img in all_imgs:\n",
    "        # Mudando a função\n",
    "        features.append(lbp_features(img, points=14, radius=2, n_bins=16))\n",
    "\n",
    "    dists = []\n",
    "    for feat in features:\n",
    "        dist = np.sum(np.abs(features[0] - feat))\n",
    "        dists.append(dist)\n",
    "    return dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.155906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.148553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.457973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.210260</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0\n",
       "1  0.000000\n",
       "2  0.155906\n",
       "3  0.148553\n",
       "4  0.457973\n",
       "5  0.210260"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dists = ex6_dist()\n",
    "pd.DataFrame(ex6_dist(), index=1 + np.arange(5))  # 3, 2, 5 é a ordem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 4, 3])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Se quisermos os índices da ordem\n",
    "ind = np.argsort(dists)\n",
    "ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.14855343, 0.15590619, 0.21026018, 0.45797315])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# se quisermos as distâncias de acordo com os índices acima\n",
    "dists = np.array(dists)\n",
    "dists[ind]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 7)\n",
    " \n",
    "No método Bag-of-Features quais das seguintes escolhas para o *framework* influenciam mais drasticamente a performance do método no caso de uso em imagens?\n",
    "\n",
    "(a) O tamanho do dicionário, a quantidade de cores nas imagens, a quantidade de classes do problema<br>\n",
    "(b) O tamanho do dicionário, o descritor base, o método utilizado para aprender o dicionário<br>\n",
    "(c) O descritor base e o número de componentes principais utilizados<br>\n",
    "(d) O tamanho do patch extraído da imagem, que deve ser compatível com a resolução das imagens<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ver discussão na gravação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercício 8)\n",
    "\n",
    "Execute o método Bag-of-Features estudado em aula, agora com os seguintes parâmetros:\n",
    "* tamanho do patch = (13, 13)\n",
    "* número de patches = 1000\n",
    "* principais componentes = 10\n",
    "* tamanho do dicionário = 50\n",
    "\n",
    "Utilize a imagem de consulta `flower.jpg` e recupere as 12 imagens mais similares utilizando o modelo BoF aprendido. Quantas imagens foram recuperadas pertencendo à mesma categoria da consulta?\n",
    "\n",
    "(a) 3<br>\n",
    "(b) 0<br>\n",
    "(c) 6<br>\n",
    "(d) 9<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from os import listdir\n",
    "from imageio import imread\n",
    "from sklearn.feature_extraction.image import extract_patches_2d\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "\n",
    "def get_patches(img_file, random_state, tam_patch=(11, 11), n_patches=250):\n",
    "    '''Extração de subimagens a partir de uma imagem\n",
    "       Parametros\n",
    "           img_file: caminho para a imagem\n",
    "           random_state: semente aleatoria\n",
    "           tam_patches: tamanho de cada subimagem\n",
    "           n_patches: numero maximo de subimagens a extrair\n",
    "    '''\n",
    "\n",
    "    img = imread(img_file)\n",
    "    \n",
    "    # Extrai subimagens\n",
    "    patch = extract_patches_2d(img, \n",
    "                               patch_size=tam_patch,\n",
    "                               max_patches=n_patches, \n",
    "                               random_state=random_state)\n",
    "    \n",
    "    # so da certo para RGB? -> Discutido durante a monitoria\n",
    "    return patch.reshape((n_patches, \n",
    "                          np.prod(tam_patch) * len(img.shape)))\n",
    "    # return patch.reshape((n_patches, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parametros do BOF\n",
    "tam_patch = (13, 13)\n",
    "n_patches = 1000\n",
    "path_imgs = './dados/flickr_map_training/'\n",
    "random_state = 1\n",
    "# pega lista de arquivos no caminho\n",
    "l_imgs = listdir(path_imgs)\n",
    "\n",
    "# total de imagens\n",
    "n_imgs = len(l_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 206 ms, sys: 8.01 ms, total: 214 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Calculando quanto tempo demora no for na mão, dps vamos comparar com a versão paralela\n",
    "for arq_img in l_imgs:\n",
    "    get_patches(path_imgs+arq_img,  random_state, tam_patch, n_patches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patches extraídos para criação do dicionário de features\n",
      "Total de imagens =  80\n",
      "Tamanho de cada array de patches =  (1000, 507)\n",
      "CPU times: user 142 ms, sys: 22.8 ms, total: 165 ms\n",
      "Wall time: 183 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fazendo de maneira paralela; na minha máquina não tem grande vantagem\n",
    "\n",
    "# Extrai patches de cada imagem, de forma paralela para cada imagem\n",
    "# retorna uma lista do mesmo tamanho do número de imagens\n",
    "patch_arr = Parallel(n_jobs=-1)(delayed(get_patches)(path_imgs+arq_img, \n",
    "                                                    random_state,\n",
    "                                                    tam_patch,\n",
    "                                                    n_patches)\n",
    "                                for arq_img in l_imgs)\n",
    "\n",
    "print('Patches extraídos para criação do dicionário de features')\n",
    "print('Total de imagens = ', len(patch_arr))\n",
    "print('Tamanho de cada array de patches = ', patch_arr[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cada patch vira uma linha\n",
    "patch_arr2 = np.array(patch_arr, copy=True)\n",
    "patch_arr2 = patch_arr2.reshape(patch_arr2.shape[0]*patch_arr2.shape[1], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando PCA\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(patch_arr2)\n",
    "patch_pca = pca.transform(patch_arr2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80000, 10)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patch_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(n_clusters=50)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fazendo o clustering que vai definir meu dicionário\n",
    "kmeans = KMeans(n_clusters=50,)\n",
    "kmeans.fit(patch_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.023, 0.   , 0.   , 0.009, 0.   , 0.   , 0.   , 0.031, 0.   ,\n",
       "       0.002, 0.003, 0.112, 0.095, 0.   , 0.   , 0.011, 0.007, 0.007,\n",
       "       0.018, 0.037, 0.001, 0.01 , 0.006, 0.012, 0.   , 0.291, 0.   ,\n",
       "       0.   , 0.107, 0.   , 0.002, 0.002, 0.011, 0.   , 0.   , 0.   ,\n",
       "       0.024, 0.003, 0.092, 0.   , 0.008, 0.04 , 0.006, 0.   , 0.006,\n",
       "       0.002, 0.022, 0.   , 0.   , 0.   ])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# O que faltaria para terminar o exercício: colocar num for e fazer 1 distância L1;\n",
    "# ver notebook com solução pro resto!\n",
    "img_kmeans = kmeans.predict(patch_pca[0:1000])\n",
    "hist_bof,_ = np.histogram(img_kmeans, bins=range(50+1), density=True)\n",
    "hist_bof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
